# -*- coding: utf-8 -*-
"""Another Datathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KvWg5K1PAqoBA9xIrMZmYWT_54G-imNq
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install -U fashion-clip

import sys
# sys.path.append("fashion-clip/")
from fashion_clip.fashion_clip import FashionCLIP
import pandas as pd
import numpy as np
from collections import Counter
from PIL import Image
import requests
from io import BytesIO

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# fclip = FashionCLIP('fashion-clip')

df = pd.read_pickle('preprocessed_data.pkl')

df.shape

import pickle
import numpy as np
from fashion_clip.fashion_clip import FashionCLIP
import tensorflow as tf
from transformers import ViTImageProcessor, ViTForImageClassification
from PIL import Image
import requests
import concurrent.futures
from itertools import zip_longest


# Load the FashionCLIP model
with open('fclip_model.pkl', 'rb') as file:
    loaded_model_data = pickle.load(file)

# Load the ViT model
processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')

# List of class labels
labels = model.config.id2label

# Keyword lists for classification
shirt_labels = ['belts', 'blazers', 'dresses', 'dupatta', 'jackets', 'kurtas', 'kurtis', 'lehenga choli', 'nehru jackets', 'rain jacket', 'bulletproof vest', 'cardigan',
        'rompers', 'shirts', 'shrug', 'suspenders', 'sweaters', 'sweatshirt', 'tops', 'T-shirt,', 'tunics', 'waistcoat', 'hoodie', 'jerrsey', 'tee shirt', 'maillot', 'fur coat'
        'wool', 'woolen', 'woollen', 'fur coat', 'brassiere', 'bra', 'bandeau', 'tank suit', 'brassiere', 'bandeau', 'sarong', 'pajama', 'pyjama', 'pj\'s', 'jammies', 'velvet',
        'bulletproof vest', 'maillot', 'tank suit', 'miniskirt', 'mini', 'sleeping bag', 'trench coat', 'lab coat', 'laboratory coat', 'velvet', 'fur coat', 'horizontal bar, high bar']
pants_labels = ['capris', 'churidar', 'jeans', 'jeggings', 'leggings', 'patiala', 'salwar', 'salwar dupatta', 'shorts', 'skirts', 'stockings',
        'swimwear', 'tights', 'track pants', 'tracksuits', 'trousers', 'blue jean', 'jean', 'denim', 'swimming trunks', 'bathing trunks']
shoes_labels = ['casual shoes', 'flats', 'flip flops', 'formal shoes', 'heels', 'sandal', 'holster', 'clog', 'geta', 'patten', 'sabot',
        'sandals', 'sports sandals', 'sports shoes', 'boot', 'running shoe', 'hair slide', 'sabot', 'cowboy hat', 'ten-gallon hat']


def chunked(iterable, n):
    args = [iter(iterable)] * n
    return zip_longest(*args)

def process_image(args):
    image_url, name, url = args
    image_url = image_url[0]  # Assuming the image URL is the first element in the list

    # Load the image from the URL
    image = Image.open(requests.get(image_url, stream=True).raw)

    # Convert the image to RGB if it has a single channel
    if image.mode != "RGB":
        image = image.convert("RGB")

    return image, name, url

def classify_product(description):
    loaded_image_embeddings = loaded_model_data['image_embeddings']
    loaded_text_embeddings = loaded_model_data['text_embeddings']
    loaded_images = loaded_model_data['images']

    fclip = FashionCLIP('fashion-clip')

    # Encode the query description
    query_text_embedding = fclip.encode_text([description], batch_size=32)[0]

    # Calculate similarity scores between the query and loaded embeddings
    similarity_scores = np.dot(query_text_embedding, loaded_image_embeddings.T)

    # Sort indices based on similarity scores in descending order
    sorted_indices = np.argsort(similarity_scores)[::-1]

    # Get the URLs of the top K most similar images
    top_k = 15
    top_similar_image_urls = [loaded_images[i] for i in sorted_indices[:top_k]]

    # Create a new DataFrame containing information of products in top_similar_image_urls
    df_top_similar = df[df['images'].apply(lambda x: any(link in x for link in top_similar_image_urls))]

    # Get the URL, name, and image information of products in top_similar_image_urls
    result_urls = df_top_similar['url'].tolist()
    result_names = df_top_similar['name'].tolist()
    result_images = df_top_similar['images'].tolist()

    # Predict and classify each image
    with concurrent.futures.ThreadPoolExecutor() as executor:
        image_results = list(executor.map(process_image, zip(result_images, result_names, result_urls)))

    class_dict = {}

    for (image, name, url), (image_url, _, _) in zip(image_results, zip(result_images, result_names, result_urls)):
        # Prepare the input data
        inputs = processor(images=np.array(image), return_tensors="pt")

        # Predict the class label
        outputs = model(**inputs)
        predicted_class_index = outputs.logits.argmax(dim=1).item()
        predicted_label = labels[predicted_class_index]

        # Classify the label as "pants", "shirt", "shoes", or "others"
        if any(label in predicted_label for label in pants_labels):
            predicted_label = "pants"
        elif any(label in predicted_label for label in shirt_labels):
            predicted_label = "shirt"
        elif any(label in predicted_label for label in shoes_labels):
            predicted_label = "shoes"
        else:
            predicted_label = "others"

        # Store the product information in the dictionary based on the label
        if predicted_label not in class_dict:
            class_dict[predicted_label] = []
        class_dict[predicted_label].append({"title":name, 'image': image_url, 'link':url})

    return class_dict

# Example usage
description = "workout"
results = classify_product(description)

for label, products in results.items():
    print(f'Label: {label}')
    for name, image_url, url in products:
        print(f'Name: {name}')
        print(f'Image: {image_url}')
        print(f'URL: {url}')
        print("---")

import pickle

# Save the classify_product function as a pickle file
with open('classify_product.pkl', 'wb') as file:
    pickle.dump(classify_product, file)